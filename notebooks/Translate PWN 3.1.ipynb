{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500b5235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:46:06.606827Z",
     "start_time": "2021-10-11T21:46:06.149390Z"
    }
   },
   "outputs": [],
   "source": [
    "import wn\n",
    "from google.cloud import translate_v2 as translate\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"wordnet_translator\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.INFO)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "consoleHandler.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6052a2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:46:10.748563Z",
     "start_time": "2021-10-11T21:46:06.609205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[KCached file found: /Users/dchaplinsky/.wn_data/downloads/49903b7403676be7b2b7463448ce7a9699599f09\n",
      "\u001b[KSkipping pwn:3.1 (Princeton WordNet 3.1); already added/T/tmptm_4sxz6/pwn31/wn31.xml\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/dchaplinsky/.wn_data/downloads/49903b7403676be7b2b7463448ce7a9699599f09')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.download(\"pwn:3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defe329b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T21:46:10.847864Z",
     "start_time": "2021-10-11T21:46:10.751615Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient('mongodb://localhost:27017/')\n",
    "db = client.wordnet\n",
    "collection = db[\"tasks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "604760fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T11:11:44.759426Z",
     "start_time": "2021-10-12T11:10:25.857183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17962a524044f79bdfac6faccaff7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117791 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 14:11:44,756 - wordnet_translator - INFO - 0 was created and 24 was updated from 'pwn:3.1'\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def populate_tasks_in_mongo(lexicon=\"pwn:3.1\", filter_func=None):\n",
    "    if filter_func is None:\n",
    "\n",
    "        filter_func = lambda synset: True\n",
    "\n",
    "    tasks_created = 0\n",
    "    tasks_updated = 0\n",
    "\n",
    "    for synset in tqdm(wn.synsets(lexicon=lexicon)):\n",
    "        if filter_func(synset):\n",
    "            words = {w.id: w.lemma() for w in synset.words()}\n",
    "            res = (\n",
    "                collection.update_one(\n",
    "                    {\"_id\": synset.id},\n",
    "                    {\n",
    "                        \"$set\": {\n",
    "                            \"ili\": synset.ili.id,\n",
    "                            \"pos\": synset.pos,\n",
    "                            \"words\": words,\n",
    "                            \"definition\": list(\n",
    "                                map(str.strip, synset.definition().split(\";\"))\n",
    "                            ),\n",
    "                        }\n",
    "                    },\n",
    "                    upsert=True,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if res.upserted_id:\n",
    "                tasks_created += 1\n",
    "            else:\n",
    "                tasks_updated += 1\n",
    "\n",
    "                \n",
    "    logger.info(\n",
    "        f\"{tasks_created} was created and {tasks_updated} was updated from '{lexicon}'\"\n",
    "    )\n",
    "\n",
    "    \n",
    "def filter_only_big_synsets_with_description(synset):\n",
    "    return len(synset.lemmas()) == 5 and synset.definition()\n",
    "\n",
    "export_samples = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "\n",
    "for pos in [\"a\", \"v\", \"n\"]:\n",
    "    for lemmas_count in range(1, 5):\n",
    "        export_samples[pos][lemmas_count] = 2\n",
    "\n",
    "\n",
    "def filter_to_have_a_nice_sample(synset):\n",
    "    global export_samples\n",
    "\n",
    "    if not synset.definition():\n",
    "        return False\n",
    "\n",
    "    if export_samples[synset.pos][len(synset.lemmas())] > 0:\n",
    "        export_samples[synset.pos][len(synset.lemmas())] -= 1\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# populate_tasks_in_mongo(filter_func=filter_only_big_synsets_with_description)\n",
    "populate_tasks_in_mongo(filter_func=filter_to_have_a_nice_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e4329b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T22:22:25.180215Z",
     "start_time": "2021-10-11T22:22:25.168273Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests, uuid, json\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class BingTranslationException(Exception):\n",
    "    pass\n",
    "\n",
    "class BingTranslator:\n",
    "    translate_path = '/translate'\n",
    "    dictionary_lookup_path = '/dictionary/lookup'\n",
    "\n",
    "\n",
    "    def __init__(self, key_file, endpoint=\"https://api.cognitive.microsofttranslator.com\"):\n",
    "        self.endpoint = endpoint\n",
    "\n",
    "        with open(key_file) as fp:\n",
    "            self.headers = json.load(fp)\n",
    "    \n",
    "    def _get_headers(self):\n",
    "        headers = self.headers.copy()\n",
    "        headers['X-ClientTraceId'] = str(uuid.uuid4())\n",
    "\n",
    "        return headers\n",
    "    \n",
    "    def _request(self, path, phrase, source_language=\"en\", target_language=\"uk\"):\n",
    "        constructed_url = urljoin(self.endpoint, path)\n",
    "\n",
    "        headers = self._get_headers()\n",
    "        params = {\n",
    "            'api-version': '3.0',\n",
    "            \"from\": source_language,\n",
    "            'to': target_language\n",
    "        }\n",
    "\n",
    "        body = [{\n",
    "            'text': phrase\n",
    "        }]\n",
    "\n",
    "        request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "\n",
    "        try:\n",
    "            response = request.json()\n",
    "        except json.JSONDecodeError:\n",
    "            raise BingTranslationException(f\"Cannot translate phrase '{phrase}' cannot parse the response as json\")\n",
    "\n",
    "        if \"error\" in response:\n",
    "            raise BingTranslationException(f\"Cannot translate phrase '{phrase}' because of an error: {response['error']}\")\n",
    "        \n",
    "        if request.status_code != 200:\n",
    "            raise BingTranslationException(f\"Cannot translate phrase '{phrase}', status code was {request.status_code}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    def translate(self, phrase, source_language=\"en\", target_language=\"uk\"):\n",
    "        response = self._request(self.translate_path, phrase, source_language, target_language)\n",
    "\n",
    "        for l in response:\n",
    "            for translation in l.get(\"translations\", []):\n",
    "                return translation[\"text\"]\n",
    "        \n",
    "        raise BingTranslationException(f\"Cannot find a translation for a phrase '{phrase}'\")\n",
    "\n",
    "    def dictionary_lookup(self, word, source_language=\"en\", target_language=\"uk\"):\n",
    "        response = self._request(self.dictionary_lookup_path, word, source_language, target_language)\n",
    "\n",
    "        for l in response:\n",
    "            return l.get(\"translations\", [])\n",
    "        \n",
    "        raise BingTranslationException(f\"Cannot find a translation for a phrase '{phrase}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55181c84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T11:16:24.678743Z",
     "start_time": "2021-10-12T11:11:44.762015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365417525be4440ab7be93c729a5ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb78161a7e54f0592036a193e1b2e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e046c0950d23491ea19b450eb4dbf4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 14:12:16,196 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:12:17,319 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:12:24,425 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:12:25,528 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:12:33,755 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:12:34,847 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b9af4687654fbcbcbaadcc15fce5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d450f1928e445669bc5aa2fb6fdce8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 14:13:37,937 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:13:39,878 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:13:52,751 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:13:54,787 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:14:09,520 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n",
      "2021-10-12 14:14:11,517 - wordnet_translator - WARNING - Cannot find 'or' in the last chunk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1035f5042a2454082b0f128a13897d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import sleep\n",
    "import itertools\n",
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def sliding_window(iterable, n=2):\n",
    "    iterables = itertools.tee(iterable, n)\n",
    "\n",
    "    for iterable, num_skipped in zip(iterables, itertools.count()):\n",
    "        for _ in range(num_skipped):\n",
    "            next(iterable, None)\n",
    "\n",
    "    return zip(*iterables)\n",
    "\n",
    "\n",
    "class AbstractTranslator:\n",
    "    def __init__(self, source_language=\"en\", target_language=\"uk\"):\n",
    "        self.source_language = source_language\n",
    "        self.target_language = target_language\n",
    "\n",
    "    def generate_samples(self, task):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def translate(self, task, sleep_between_samples=1):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def parse_results(self, results):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def method_id(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class AbstractSlidingWindowTranslator(AbstractTranslator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        group_by=3,\n",
    "        add_or=True,\n",
    "        add_quotes=True,\n",
    "        combine_in_one=True,\n",
    "        add_aux_words=True,\n",
    "        source_language=\"en\",\n",
    "        target_language=\"uk\",\n",
    "    ):\n",
    "        super().__init__(source_language=source_language, target_language=target_language)\n",
    "\n",
    "        self.group_by = group_by\n",
    "        self.add_or = add_or\n",
    "        self.add_quotes = add_quotes\n",
    "        self.combine_in_one = combine_in_one\n",
    "        self.add_aux_words = add_aux_words\n",
    "\n",
    "    def method_id(self):\n",
    "        return f\"{type(self).__name__}(group_by={self.group_by},add_or={self.add_or},add_quotes={self.add_quotes},combine_in_one={self.combine_in_one},add_aux_words={self.add_aux_words})\"\n",
    "\n",
    "    def generate_samples(self, task):\n",
    "        samples = []\n",
    "        total_samples = 0\n",
    "        words = list(task[\"words\"].values())\n",
    "\n",
    "        if self.add_aux_words:\n",
    "            if task[\"pos\"] == \"v\":\n",
    "                words = [f\"to {w}\" for w in words]\n",
    "            elif task[\"pos\"] == \"n\":\n",
    "                words = [f\"the {w}\" for w in words]\n",
    "\n",
    "        if self.add_quotes:\n",
    "            words = [f'\"{w}\"' for w in words]\n",
    "\n",
    "        if len(words) < self.group_by:\n",
    "            chunks = [words]\n",
    "        else:\n",
    "            chunks = sliding_window(words, self.group_by)\n",
    "\n",
    "        for chunk in chunks:\n",
    "            total_samples += len(chunk)\n",
    "\n",
    "            if self.add_or and len(chunk) > 1:\n",
    "                lemmas = \", \".join(chunk[:-1]) + f\" or {chunk[-1]}\"\n",
    "            else:\n",
    "                lemmas = \", \".join(chunk)\n",
    "\n",
    "            if task[\"definition\"]:\n",
    "                samples.append(f\"{lemmas}: {task['definition'][0]}\")\n",
    "            else:\n",
    "                samples.append(lemmas)\n",
    "\n",
    "        if self.combine_in_one:\n",
    "            return {\"samples\": [\"<br/>\\n\\n\".join(samples)], \"total_lemmas\": total_samples}\n",
    "        else:\n",
    "            return {\"samples\": samples, \"total_lemmas\": total_samples}\n",
    "\n",
    "    def estimate_tasks(self, tasks, price_per_mb=1.0 / 1024 / 1024):\n",
    "        total_len = 0\n",
    "        for task in tasks:\n",
    "            samples = self.generate_samples(task)[\"samples\"]\n",
    "            for sample in samples:\n",
    "                total_len += len(sample)\n",
    "\n",
    "        return (float(total_len) / 1024 / 1024) * price_per_mb\n",
    "\n",
    "    def _parse_result(self, result):\n",
    "        all_terms = []\n",
    "        all_definitions = []\n",
    "        for l in filter(None, result.replace(\"<br/>\", \"\\n\").split(\"\\n\")):\n",
    "            if \":\" not in l:\n",
    "                logger.warning(\"Cannot find a semicolon in the translated text\")\n",
    "                continue\n",
    "\n",
    "            terms, definition = l.split(\":\", 1)\n",
    "            terms = list(map(str.strip, terms.split(\",\")))\n",
    "\n",
    "            if self.add_or:\n",
    "                for or_word in [\"чи то\", \"чи\", \"або\", \"альбо\", \"or\"]:\n",
    "                    splits = re.split(f\"[,\\s]+{or_word}[,\\s]+\", terms[-1], flags=re.I)\n",
    "                    if len(splits) > 1:\n",
    "                        terms = terms[:-1] + list(map(lambda x: x.strip(\", \"), splits))\n",
    "                        break\n",
    "                else:\n",
    "                    if self.group_by > 1:\n",
    "                        logger.warning(\"Cannot find 'or' in the last chunk\")\n",
    "\n",
    "            if self.add_quotes:\n",
    "                terms = [term.strip('\"\\'\"«»') for term in terms]\n",
    "\n",
    "            all_terms += terms\n",
    "            all_definitions.append(definition.strip())\n",
    "\n",
    "        return {\"all_terms\": all_terms, \"all_definitions\": all_definitions}\n",
    "\n",
    "\n",
    "class SlidingWindowGoogleTranslator(AbstractSlidingWindowTranslator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gcloud_credentials,\n",
    "        group_by=3,\n",
    "        add_or=True,\n",
    "        add_quotes=True,\n",
    "        combine_in_one=True,\n",
    "        add_aux_words=True,\n",
    "        source_language=\"en\",\n",
    "        target_language=\"uk\",\n",
    "    ):\n",
    "\n",
    "        self.gtrans_client = translate.Client.from_service_account_json(gcloud_credentials)\n",
    "        super().__init__(\n",
    "            group_by=group_by,\n",
    "            add_or=add_or,\n",
    "            add_quotes=add_quotes,\n",
    "            combine_in_one=combine_in_one,\n",
    "            add_aux_words=add_aux_words,\n",
    "            source_language=source_language,\n",
    "            target_language=target_language,\n",
    "        )\n",
    "\n",
    "    def translate(self, task, sleep_between_samples=1):\n",
    "        results = []\n",
    "        sampled = self.generate_samples(task)\n",
    "        for sample in sampled[\"samples\"]:\n",
    "            results.append(\n",
    "                self.gtrans_client.translate(\n",
    "                    sample,\n",
    "                    source_language=self.source_language,\n",
    "                    target_language=self.target_language,\n",
    "                )\n",
    "            )\n",
    "            sleep(sleep_between_samples)\n",
    "\n",
    "        return self.parse_results(results)\n",
    "\n",
    "    def parse_results(self, results):\n",
    "        terms = Counter()\n",
    "        definitions = Counter()\n",
    "        parsed_results = []\n",
    "\n",
    "        for r in results:\n",
    "            parsed = self._parse_result(html.unescape(r.get(\"translatedText\", \"\")))\n",
    "            terms.update(parsed[\"all_terms\"])\n",
    "            definitions.update(parsed[\"all_definitions\"])\n",
    "            parsed_results.append(parsed)\n",
    "\n",
    "        return {\n",
    "            \"raw\": parsed_results,\n",
    "            \"terms\": terms.most_common(),\n",
    "            \"definitions\": definitions.most_common(),\n",
    "            \"type\": \"translator\",\n",
    "        }\n",
    "\n",
    "    def estimate_tasks(self, tasks, price_per_mb=20):\n",
    "        return super().estimate_tasks(tasks, price_per_mb)\n",
    "\n",
    "\n",
    "class SlidingWindowBingTranslator(AbstractSlidingWindowTranslator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bing_apikey,\n",
    "        group_by=3,\n",
    "        add_or=True,\n",
    "        add_quotes=True,\n",
    "        combine_in_one=True,\n",
    "        add_aux_words=True,\n",
    "        source_language=\"en\",\n",
    "        target_language=\"uk\",\n",
    "    ):\n",
    "        self.bing_apikey = bing_apikey\n",
    "        self.bing_translator = BingTranslator(self.bing_apikey)\n",
    "\n",
    "        super().__init__(\n",
    "            group_by=group_by,\n",
    "            add_or=add_or,\n",
    "            add_quotes=add_quotes,\n",
    "            combine_in_one=combine_in_one,\n",
    "            add_aux_words=add_aux_words,\n",
    "            source_language=source_language,\n",
    "            target_language=target_language,\n",
    "        )\n",
    "\n",
    "    def estimate_tasks(self, tasks, price_per_mb=10):\n",
    "        return super().estimate_tasks(tasks, price_per_mb)\n",
    "\n",
    "    def translate(self, task, sleep_between_samples=1):\n",
    "        results = []\n",
    "        sampled = self.generate_samples(task)\n",
    "        for sample in sampled[\"samples\"]:\n",
    "            results.append(\n",
    "                self.bing_translator.translate(\n",
    "                    sample,\n",
    "                    source_language=self.source_language,\n",
    "                    target_language=self.target_language,\n",
    "                )\n",
    "            )\n",
    "            sleep(sleep_between_samples)\n",
    "\n",
    "        return self.parse_results(results)\n",
    "\n",
    "    def parse_results(self, results):\n",
    "        terms = Counter()\n",
    "        definitions = Counter()\n",
    "        parsed_results = []\n",
    "\n",
    "        for r in results:\n",
    "            parsed = self._parse_result(html.unescape(r))\n",
    "            terms.update(parsed[\"all_terms\"])\n",
    "            definitions.update(parsed[\"all_definitions\"])\n",
    "            parsed_results.append(parsed)\n",
    "\n",
    "        return {\n",
    "            \"raw\": parsed_results,\n",
    "            \"terms\": terms.most_common(),\n",
    "            \"definitions\": definitions.most_common(),\n",
    "            \"type\": \"translator\",\n",
    "        }\n",
    "\n",
    "class AbstractDictionaryTranslator(AbstractTranslator):\n",
    "    def generate_samples(self, task):\n",
    "        return {\"samples\": list(task[\"words\"].values()), \"total_lemmas\": len(task[\"words\"]), \"pos\": task[\"pos\"]}\n",
    "\n",
    "\n",
    "class DictionaryBingTranslator(AbstractDictionaryTranslator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bing_apikey,\n",
    "        source_language=\"en\",\n",
    "        target_language=\"uk\",\n",
    "    ):\n",
    "        self.bing_apikey = bing_apikey\n",
    "        self.bing_translator = BingTranslator(self.bing_apikey)\n",
    "\n",
    "        super().__init__(\n",
    "            source_language=source_language,\n",
    "            target_language=target_language,\n",
    "        )\n",
    "\n",
    "#     [ \"a\", \"n\", \"r\", \"s\", \"v\" ]\n",
    "# a ADJ\n",
    "# r ADV\n",
    "# c CONJ\n",
    "# n NOUN\n",
    "# v VERB\n",
    "# x OTHER\n",
    "\n",
    "# DET\n",
    "# MODAL\n",
    "# PREP\n",
    "# PRON\n",
    "# Марьяна Романишин, [12 жовт. 2021 р., 09:18:00]:\n",
    "# Так, у цьому випадку adposition - це preposition. У різних мовах прийменники можуть стояти перед іменником (preposition) або після іменника (postposition). Термін adposition об'єднує одне і друге.\n",
    "\n",
    "# s також можна змапити на ADJ.\n",
    "\n",
    "    def translate(self, task, sleep_between_samples=1):\n",
    "        results = []\n",
    "        sampled = self.generate_samples(task)\n",
    "        for sample in sampled[\"samples\"]:\n",
    "            results.append(\n",
    "                self.bing_translator.dictionary_lookup(\n",
    "                    sample,\n",
    "                    source_language=self.source_language,\n",
    "                    target_language=self.target_language,\n",
    "                )\n",
    "            )\n",
    "            sleep(sleep_between_samples)\n",
    "\n",
    "        return self.parse_results(results)\n",
    "\n",
    "    def parse_results(self, results):\n",
    "        terms = Counter()\n",
    "        parsed_results = []\n",
    "\n",
    "        for r in results:\n",
    "            if \"normalizedTarget\" in r:\n",
    "                terms.update(r[\"normalizedTarget\"])\n",
    "            parsed_results.append(r)\n",
    "\n",
    "        return {\n",
    "            \"raw\": parsed_results,\n",
    "            \"terms\": terms.most_common(),\n",
    "            \"definitions\": [],\n",
    "            \"type\": \"dictionary\",\n",
    "        }\n",
    "    def method_id(self):\n",
    "        return f\"{type(self).__name__}()\"\n",
    "\n",
    "translators = [\n",
    "    SlidingWindowGoogleTranslator(\"../api_keys/dchaplynskyi_gmail_com.json\", group_by=1),\n",
    "    SlidingWindowGoogleTranslator(\"../api_keys/dchaplynskyi_gmail_com.json\", group_by=3),\n",
    "    SlidingWindowBingTranslator(\"../api_keys/khrystyna_skopyk_gmail_com.json\", group_by=1),\n",
    "    SlidingWindowBingTranslator(\"../api_keys/khrystyna_skopyk_gmail_com.json\", group_by=3),\n",
    "    DictionaryBingTranslator(\"../api_keys/khrystyna_skopyk_gmail_com.json\"),\n",
    "]\n",
    "\n",
    "# tasks = list(collection.find(\n",
    "#     {\n",
    "#         \"_id\": {\n",
    "#             \"$in\": [\n",
    "#                 # VERBS\n",
    "#                 \"pwn-00006238-v\",\n",
    "#                 \"pwn-00009140-v\",\n",
    "#                 \"pwn-00014735-v\",\n",
    "# #                 \"pwn-00018151-v\",\n",
    "# #                 \"pwn-00022309-v\",\n",
    "# #                 \"pwn-00023466-v\",\n",
    "# #                 \"pwn-00050369-v\",\n",
    "# #                 \"pwn-00056644-v\",\n",
    "# #                 \"pwn-00058790-v\",\n",
    "# #                 \"pwn-00067045-v\",\n",
    "                \n",
    "#                 # NOUNS:\n",
    "#                 \"pwn-00109001-n\",\n",
    "#                 \"pwn-00284945-n\",\n",
    "#                 \"pwn-00224850-n\",\n",
    "#                 # ADJS:\n",
    "#                 \"pwn-00102561-a\",\n",
    "#             ]\n",
    "#         }\n",
    "#     }\n",
    "# ))\n",
    "\n",
    "tasks = list(collection.find())\n",
    "\n",
    "for translator in tqdm(translators):\n",
    "    for t in tqdm(tasks):\n",
    "        if translator.method_id() not in t.get(\"results\", {}):\n",
    "            res = translator.translate(t)\n",
    "            collection.update_one(\n",
    "                {\"_id\": t[\"_id\"]}, {\"$set\": {f\"results.{translator.method_id()}\": res}}, upsert=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "259a5710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T11:59:27.312877Z",
     "start_time": "2021-10-12T11:59:27.291890Z"
    }
   },
   "outputs": [],
   "source": [
    "from csv import DictWriter\n",
    "\n",
    "def render_counter(cnt):\n",
    "    return \"\\n\".join(f\"{k}: {v}\" for k, v in cnt.most_common())\n",
    "\n",
    "answered = list(collection.find({\"results\": {\"$exists\": 1}}))\n",
    "methods = set()\n",
    "\n",
    "for l in answered:\n",
    "    methods |= set(l[\"results\"].keys())\n",
    "\n",
    "columns = [\"pwn\", \"lemmas\", \"pos\", \"definition\"]\n",
    "\n",
    "for method in sorted(methods):\n",
    "    columns.append(f\"Terms, {method}\")\n",
    "    columns.append(f\"Definitions, {method}\")\n",
    "\n",
    "columns.append(\"Terms combined\")\n",
    "columns.append(\"Definitions combined\")\n",
    "\n",
    "\n",
    "with open(\"/tmp/translations.csv\", \"w\") as fp:\n",
    "    w = DictWriter(fp, fieldnames=columns)\n",
    "\n",
    "    w.writeheader()\n",
    "\n",
    "    for t in answered:\n",
    "        to_export = {\n",
    "            \"pwn\": t[\"_id\"],\n",
    "            \"definition\": \"\\n\".join(t[\"definition\"]),\n",
    "            \"pos\": t[\"pos\"],\n",
    "            \"lemmas\": \"\\n\".join(t[\"words\"].values()),\n",
    "        }\n",
    "\n",
    "        combined_terms = Counter()\n",
    "        combined_definitions = Counter()\n",
    "\n",
    "        for method, r in t.get(\"results\", {}).items():\n",
    "            terms = Counter(dict(r.get(\"terms\", [])))\n",
    "            definitions = Counter(dict(r.get(\"definitions\", [])))\n",
    "            combined_terms.update({k.lower(): v for k, v in terms.items()})\n",
    "            combined_definitions.update({k.lower(): v for k, v in definitions.items()})\n",
    "\n",
    "            to_export[f\"Terms, {method}\"] = render_counter(terms)\n",
    "            to_export[f\"Definitions, {method}\"] =  render_counter(definitions)\n",
    "\n",
    "\n",
    "        to_export[\"Terms combined\"] = render_counter(combined_terms)\n",
    "        to_export[\"Definitions combined\"] =  render_counter(combined_definitions)\n",
    "\n",
    "        w.writerow(to_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
